# Script that uses Flywheel SDK to loop through sessions in a
# Flywheel project, look for requisite files in the session and
# if the files are found then queue up the Pediatric Processing
# Gear to run on the files.
#
# GENERAL PROCESS:
#   For every session in the project:
#   1. look if the gear has already been run (if so, skip this session)
#   2. if the gear hasn't been run in this session yet, then
#       find the requisite files & define the input
#   3. run the "gear2run" and attach to the session

import flywheel
from datetime import datetime

fw = flywheel.Client()

# define Flywheel project to run the gear within
proj_name = 'Deface'

# define input file names to use as T1/T1CE/T2/FLAIR
#       NOTE: this requires all files to have similar names across subjects/sessions
#       in the Flywheel project, code will find
#       file names based on sub-string matching.
t1_fn = 'T1_to_SRI'
t1ce_fn = 'T1CE_to_SRI'
t2_fn = 'T2_to_SRI'
fl_fn = 'FL_to_SRI'

# define the gear name (needs to match that in Flywheel config file)
gear_name = 'd3b-ped-proc-pipeline'

# =================================================================
project = fw.projects.find_first(f'label={proj_name}')

## Initialize gear stuff
gear2run = fw.lookup(f'gears/{gear_name}')
job_list = list()

# Loop over all sessions in the project
for ses in project.sessions.iter():
    # initialize gear stuff
    inputs = {'FLAIR':[], \
                'T1':[], \
                'T1CE':[], \
                'T2':[]
                }
    input_files = 0
    # get info
    ses_label = ses.label
    sub_label = ses.subject.label
    # Make sure we have all our analysis since we got the session through an iterator, and not "fw.get()'
    ses = ses.reload()
    analyses = ses.analyses
    # If there are no analyses containers, we know that this gear was not run. 
    if len(analyses) == 0:
        run_flag = 1
    # Otherwise there are analyses containers
    else:
        # print(f'{ses.label} has analysis')
        # Check to see if any were generated by our gear
        matches = [asys for asys in analyses if asys.gear_info.get('name') == gear2run]
        # print(f'{len(matches)} matches in {[asys.label for asys in analyses]}')
        # If there are no matches, the gear didn't run
        if len(matches) == 0:
            run_flag = 1
        else:
            run_flag = 0
            print(f'Gear already run! (skipping): {sub_label}/{ses_label}')
    if run_flag == 1:
        # loop through the acquisitions in the session
        for acq in ses.acquisitions.iter():
            # see if there are any files with names that match
            # the inputs
            for file_obj in acq.files:
                fname = file_obj.name
                if fl_fn in fname:
                    inputs['FLAIR'] = file_obj
                    input_files+=1
                elif t1_fn in fname:
                    inputs['T1'] = file_obj
                    input_files+=1
                elif t1ce_fn in fname:
                    inputs['T1CE'] = file_obj
                    input_files+=1
                elif t2_fn in fname:
                    inputs['T2'] = file_obj
                    input_files+=1
        if input_files==4: # if all input files are defined
            dest = ses # The destination for this anlysis (e.g., subj or session container)
            time_fmt = '%m/%d/%Y %H:%M:%S'
            analysis_label = f'{gear_name} {datetime.now().strftime(time_fmt)}'
            job_id = gear2run.run(analysis_label=analysis_label, \
                                        inputs=inputs, \
                                        destination=dest ) # config={'Subject':subject.label}
            job_list.append(job_id)
            print(f'Queued: {sub_label}/{ses_label} - {analysis_label}')
        else:
            print(f'MISSING REQUISITE FILES (skipping): {sub_label}/{ses_label}')
